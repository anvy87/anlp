{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bigram_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM6i1LeCpMYdWk9MX/Ysyhv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anvy87/anlp/blob/master/bigram_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxecYAwrL4XZ"
      },
      "source": [
        "# compute the bigram model\n",
        "def build_bigram_model():\n",
        "  bigram_model = collections.defaultdict(\n",
        "      lambda: collections.defaultdict(lambda: 0))\n",
        "  for sentence in kinematics_corpus.sents():\n",
        "    sentence = [word.lower() for word in sentence\n",
        "                if word.isalpha()]  # get alpha only\n",
        "    # Collect all bigrams counts for (w1,w2)\n",
        "    for w1, w2 in bigrams(sentence):\n",
        "      bigram_model[w1][w2] += 1\n",
        "    # compute the probability for the bigram containing w1\n",
        "    for w1 in bigram_model:\n",
        "      #total count of bigrams containing w1\n",
        "      total_count = float(sum(bigram_model[w1].values()))\n",
        "      #distribute the probability mass for all bigrams starting with w1\n",
        "      for w2 in bigram_model[w1]:\n",
        "        bigram_model[w1][w2] /= total_count\n",
        "    return bigram_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "impWRm3gOle1"
      },
      "source": [
        "def predict _next_word(first_word):\n",
        "  #build the model\n",
        "  model = build_bigram_model()\n",
        "  #get the nect for the bigram starting with 'word'\n",
        "  second_word = model(first_word)\n",
        "  #get the top 10 words whose first word is 'first_word'\n",
        "  top10words = Counter(second_word).most_common(10)\n",
        "\n",
        "  predicted_words = list(zip(*top10words))[0]\n",
        "  probability_score = list(zip(*top10words))[1]\n",
        "  x_pos = np.arrange(len(predicted_words))\n",
        "\n",
        "  plt.bar(x_pos, probability_score, align='center')\n",
        "  plt.xticks(x_pos, predicted_words)\n",
        "  plt.ylabel('Probability Score')\n",
        "  plt.xlabel('Predicted Words')\n",
        "  plt.title('Predicted words for ' + first_word)\n",
        "  plt.show()\n",
        "\n",
        "predicted_next_word('how')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}